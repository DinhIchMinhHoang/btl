{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DinhIchMinhHoang/btl/blob/main/viXTTS_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv6wKD48of3x"
      },
      "source": [
        "# 🔥🔥🔥**viXTTS Demo**🗣️🗣️🗣️\n",
        "\n",
        "Demo này giúp bạn chạy viXTTS miễn phí trên Google Colab!\n",
        "Xem thông tin mô hình tại [đây](https://huggingface.co/capleaf/viXTTS)\n",
        "\n",
        "Bạn có thể dùng demo này với mục đích:\n",
        "- ✅Mục đích cá nhân, học tập, nghiên cứu, thử nghiệm\n",
        "\n",
        "Bạn **KHÔNG** được dùng demo này với mục đích:\n",
        "- ❌Mục đích trái đạo đức, vi phạm pháp luật Việt Nam\n",
        "- ❌Tạo ra nội dung gây thù ghét, kỳ thị, bạo lực hoặc nội dung vi phạm bản quyền\n",
        "- ❌Giả mạo danh tính hoặc gây hiểu nhầm rằng nội dung được tạo ra bởi một cá nhân hoặc tổ chức khác"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kIEFgM3gnEZm",
        "outputId": "05716b63-4e63-4320-e22b-bfc446a55037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.82)] [Co\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [2 InRelease 64.9 kB/128 kB 51%] [Connecting to security.ubuntu.com (91.189.\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [2 InRelease 102 kB/128 kB 80%] [Connecting to security.ubuntu.com (91.189.9\r                                                                               \rHit:5 https://cli.github.com/packages stable InRelease\n",
            "\r0% [2 InRelease 102 kB/128 kB 80%] [Connecting to security.ubuntu.com (91.189.9\r0% [2 InRelease 111 kB/128 kB 87%] [Waiting for headers] [Connecting to r2u.sta\r0% [Waiting for headers] [Waiting for headers] [Connecting to r2u.stat.illinois\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "\r0% [6 InRelease 12.7 kB/127 kB 10%] [Waiting for headers] [Connecting to r2u.st\r0% [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)]\r                                                                               \rHit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)]\r                                                                               \rHit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)]\r                                                                               \rHit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,961 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,623 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,579 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,310 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,790 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,374 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,238 kB]\n",
            "Fetched 28.3 MB in 3s (9,417 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3-distutils set to manually installed.\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.11).\n",
            "python3.10 set to manually installed.\n",
            "python3.10-dev is already the newest version (3.10.12-1~22.04.11).\n",
            "python3.10-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.12   2         auto mode\n",
            "  1            /usr/bin/python3.10   1         manual mode\n",
            "  2            /usr/bin/python3.12   2         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: ^C\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pip]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pip-25.2 setuptools-80.9.0 wheel-0.45.1\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.10 python3.10-dev python3.10-distutils -y\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "!sudo update-alternatives --config python3\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cập nhật pip & công cụ build\n",
        "!pip install --upgrade pip setuptools wheel\n",
        "\n",
        "# Cài maturin trước để tránh lỗi build Rust module\n",
        "!pip install maturin\n",
        "\n",
        "# Clone repo viXTTS từ nhánh add-vietnamese-xtts\n",
        "!rm -rf TTS\n",
        "!git clone --branch add-vietnamese-xtts https://github.com/thinhlpg/TTS.git\n",
        "%cd TTS\n",
        "\n",
        "# Cài đặt các dependency\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Cài TTS ở chế độ editable\n",
        "!pip install -e .\n",
        "\n",
        "# Fix conflict websockets với Colab\n",
        "!pip install websockets==13.0.1\n",
        "\n",
        "# Cài đặt các thư viện bổ sung cần cho viXTTS\n",
        "!pip install deepspeed vinorm==2.0.7 cutlet unidic==1.1.0 underthesea gradio==4.35 deepfilternet==0.5.6\n",
        "\n",
        "# Tải bộ từ điển tiếng Nhật cho cutlet/unidic (bắt buộc)\n",
        "import os\n",
        "os.system(\"python -m unidic download\")\n"
      ],
      "metadata": {
        "id": "fXEZQdo19k3G",
        "outputId": "8d79645e-3091-4197-a3b8-ff51a18e7f95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (25.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.45.1)\n",
            "Collecting maturin\n",
            "  Downloading maturin-1.9.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.musllinux_1_1_x86_64.whl.metadata (16 kB)\n",
            "Collecting tomli>=1.1.0 (from maturin)\n",
            "  Downloading tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading maturin-1.9.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.musllinux_1_1_x86_64.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m133.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: tomli, maturin\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [maturin]\n",
            "\u001b[1A\u001b[2KSuccessfully installed maturin-1.9.4 tomli-2.2.1\n",
            "Cloning into 'TTS'...\n",
            "remote: Enumerating objects: 28904, done.\u001b[K\n",
            "remote: Total 28904 (delta 0), reused 0 (delta 0), pack-reused 28904 (from 1)\u001b[K\n",
            "Receiving objects: 100% (28904/28904), 136.14 MiB | 28.67 MiB/s, done.\n",
            "Resolving deltas: 100% (20953/20953), done.\n",
            "/content/TTS\n",
            "Ignoring numpy: markers 'python_version > \"3.10\"' don't match your environment\n",
            "Ignoring numba: markers 'python_version < \"3.9\"' don't match your environment\n",
            "Collecting numpy==1.22.0 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting cython>=0.29.30 (from -r requirements.txt (line 4))\n",
            "  Downloading cython-3.1.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting scipy>=1.11.2 (from -r requirements.txt (line 5))\n",
            "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting torch>=2.1 (from -r requirements.txt (line 6))\n",
            "  Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchaudio (from -r requirements.txt (line 7))\n",
            "  Downloading torchaudio-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting soundfile>=0.12.0 (from -r requirements.txt (line 8))\n",
            "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
            "Collecting librosa>=0.10.0 (from -r requirements.txt (line 9))\n",
            "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting scikit-learn>=1.3.0 (from -r requirements.txt (line 10))\n",
            "  Downloading scikit_learn-1.7.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting numba>=0.57.0 (from -r requirements.txt (line 12))\n",
            "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting inflect>=5.6.0 (from -r requirements.txt (line 13))\n",
            "  Downloading inflect-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tqdm>=4.64.1 (from -r requirements.txt (line 14))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting anyascii>=0.3.0 (from -r requirements.txt (line 15))\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyyaml>=6.0 (from -r requirements.txt (line 16))\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting fsspec>=2023.6.0 (from -r requirements.txt (line 17))\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting aiohttp>=3.8.1 (from -r requirements.txt (line 18))\n",
            "  Downloading aiohttp-3.12.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting packaging>=23.1 (from -r requirements.txt (line 19))\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting mutagen==1.47.0 (from -r requirements.txt (line 20))\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting flask>=2.0.1 (from -r requirements.txt (line 22))\n",
            "  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pysbd>=0.3.4 (from -r requirements.txt (line 24))\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting umap-learn>=0.5.1 (from -r requirements.txt (line 26))\n",
            "  Downloading umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pandas<2.0,>=1.4 (from -r requirements.txt (line 27))\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting matplotlib>=3.7.0 (from -r requirements.txt (line 29))\n",
            "  Downloading matplotlib-3.10.6-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting trainer>=0.0.36 (from -r requirements.txt (line 31))\n",
            "  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting coqpit>=0.0.16 (from -r requirements.txt (line 33))\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jieba (from -r requirements.txt (line 35))\n",
            "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pypinyin (from -r requirements.txt (line 36))\n",
            "  Downloading pypinyin-0.55.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hangul_romanize (from -r requirements.txt (line 38))\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from -r requirements.txt (line 42))\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting nltk (from -r requirements.txt (line 43))\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting g2pkk>=0.1.1 (from -r requirements.txt (line 44))\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting bangla (from -r requirements.txt (line 46))\n",
            "  Downloading bangla-0.0.5-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting bnnumerizer (from -r requirements.txt (line 47))\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer (from -r requirements.txt (line 48))\n",
            "  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting einops>=0.6.0 (from -r requirements.txt (line 50))\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers>=4.33.0 (from -r requirements.txt (line 51))\n",
            "  Downloading transformers-4.56.0-py3-none-any.whl.metadata (40 kB)\n",
            "Collecting encodec>=0.1.1 (from -r requirements.txt (line 53))\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode>=1.3.2 (from -r requirements.txt (line 55))\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting num2words (from -r requirements.txt (line 56))\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting spacy>=3 (from spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading spacy-3.8.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting Babel<3.0.0,>=2.8.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n",
            "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading gruut_lang_en-2.0.1.tar.gz (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading gruut_lang_de-2.0.1.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading gruut_lang_es-2.0.1.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dateutil>=2.8.1 (from pandas<2.0,>=1.4->-r requirements.txt (line 27))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.0,>=1.4->-r requirements.txt (line 27))\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting docopt>=0.6.2 (from num2words->-r requirements.txt (line 56))\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting regex!=2019.02.19,!=2021.8.27 (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading regex-2025.9.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting tzlocal (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40))\n",
            "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->-r requirements.txt (line 40)) (1.16.0)\n",
            "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scipy>=1.11.2 (from -r requirements.txt (line 5))\n",
            "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "  Downloading scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "  Downloading scipy-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "INFO: pip is still looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting filelock (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting jinja2 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton==3.4.0->torch>=2.1->-r requirements.txt (line 6)) (80.9.0)\n",
            "Collecting cffi>=1.0 (from soundfile>=0.12.0->-r requirements.txt (line 8))\n",
            "  Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting audioread>=2.1.9 (from librosa>=0.10.0->-r requirements.txt (line 9))\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa>=0.10.0 (from -r requirements.txt (line 9))\n",
            "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Downloading librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0.post2-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0.post1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting joblib>=0.14 (from librosa>=0.10.0->-r requirements.txt (line 9))\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting decorator>=4.3.0 (from librosa>=0.10.0->-r requirements.txt (line 9))\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pooch>=1.0 (from librosa>=0.10.0->-r requirements.txt (line 9))\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting soxr>=0.3.2 (from librosa>=0.10.0->-r requirements.txt (line 9))\n",
            "  Downloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting lazy-loader>=0.1 (from librosa>=0.10.0->-r requirements.txt (line 9))\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting msgpack>=1.0 (from librosa>=0.10.0->-r requirements.txt (line 9))\n",
            "  Downloading msgpack-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.0->-r requirements.txt (line 10))\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.57.0->-r requirements.txt (line 12))\n",
            "  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "INFO: pip is looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting numba>=0.57.0 (from -r requirements.txt (line 12))\n",
            "  Downloading numba-0.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.57.0->-r requirements.txt (line 12))\n",
            "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/lib/python3/dist-packages (from inflect>=5.6.0->-r requirements.txt (line 13)) (8.10.0)\n",
            "Collecting typeguard>=4.0.1 (from inflect>=5.6.0->-r requirements.txt (line 13))\n",
            "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.8.1->-r requirements.txt (line 18))\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp>=3.8.1->-r requirements.txt (line 18))\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp>=3.8.1->-r requirements.txt (line 18))\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp>=3.8.1->-r requirements.txt (line 18))\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp>=3.8.1->-r requirements.txt (line 18))\n",
            "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.8.1->-r requirements.txt (line 18))\n",
            "  Downloading multidict-6.6.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp>=3.8.1->-r requirements.txt (line 18))\n",
            "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.8.1->-r requirements.txt (line 18))\n",
            "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp>=3.8.1->-r requirements.txt (line 18))\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting blinker>=1.9.0 (from flask>=2.0.1->-r requirements.txt (line 22))\n",
            "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting click>=8.1.3 (from flask>=2.0.1->-r requirements.txt (line 22))\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting itsdangerous>=2.2.0 (from flask>=2.0.1->-r requirements.txt (line 22))\n",
            "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting markupsafe>=2.1.1 (from flask>=2.0.1->-r requirements.txt (line 22))\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting werkzeug>=3.1.0 (from flask>=2.0.1->-r requirements.txt (line 22))\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "INFO: pip is looking at multiple versions of umap-learn to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting umap-learn>=0.5.1 (from -r requirements.txt (line 26))\n",
            "  Downloading umap_learn-0.5.8-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->-r requirements.txt (line 26))\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.7.0->-r requirements.txt (line 29))\n",
            "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=3.7.0->-r requirements.txt (line 29))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=3.7.0->-r requirements.txt (line 29))\n",
            "  Downloading fonttools-4.59.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (109 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.7.0->-r requirements.txt (line 29))\n",
            "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting matplotlib>=3.7.0 (from -r requirements.txt (line 29))\n",
            "  Downloading matplotlib-3.10.5-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "  Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "  Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "  Downloading matplotlib-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "  Downloading matplotlib-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "INFO: pip is still looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading matplotlib-3.9.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "  Downloading matplotlib-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "  Downloading matplotlib-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting pillow>=8 (from matplotlib>=3.7.0->-r requirements.txt (line 29))\n",
            "  Downloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 29)) (2.4.7)\n",
            "Collecting psutil (from trainer>=0.0.36->-r requirements.txt (line 31))\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting tensorboard (from trainer>=0.0.36->-r requirements.txt (line 31))\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers>=4.33.0->-r requirements.txt (line 51))\n",
            "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting requests (from transformers>=4.33.0->-r requirements.txt (line 51))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.33.0->-r requirements.txt (line 51))\n",
            "  Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers>=4.33.0->-r requirements.txt (line 51))\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers>=4.33.0->-r requirements.txt (line 51))\n",
            "  Downloading hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading murmurhash-1.0.13-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading cymem-2.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading preshed-3.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading thinc-8.3.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading srsly-2.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.5.0,>=0.1.0 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typer<1.0.0,>=0.3.0 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading typer-0.17.3-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers>=4.33.0->-r requirements.txt (line 51))\n",
            "  Downloading charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers>=4.33.0->-r requirements.txt (line 51))\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers>=4.33.0->-r requirements.txt (line 51))\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading blis-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading thinc-8.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading blis-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading cloudpathlib-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading wrapt-1.17.3-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.0->-r requirements.txt (line 8))\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.7.0->-r requirements.txt (line 29))\n",
            "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading marisa_trie-1.3.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting platformdirs>=2.5.0 (from pooch>=1.0->librosa>=0.10.0->-r requirements.txt (line 9))\n",
            "  Downloading platformdirs-4.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading SudachiPy-0.6.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting sudachidict_core>=20211220 (from spacy[ja]>=3->-r requirements.txt (line 57))\n",
            "  Downloading sudachidict_core-20250825-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.1->-r requirements.txt (line 6))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard->trainer>=0.0.36->-r requirements.txt (line 31))\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard->trainer>=0.0.36->-r requirements.txt (line 31))\n",
            "  Downloading grpcio-1.74.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard->trainer>=0.0.36->-r requirements.txt (line 31)) (3.3.6)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->trainer>=0.0.36->-r requirements.txt (line 31))\n",
            "  Downloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->trainer>=0.0.36->-r requirements.txt (line 31))\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m193.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m182.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m189.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cython-3.1.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (888.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.0/888.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m  \u001b[33m0:00:26\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m186.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m322.2/322.4 MB\u001b[0m \u001b[31m155.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "snapshot_download(\n",
        "    repo_id=\"thinhlpg/viXTTS\",\n",
        "    repo_type=\"model\",\n",
        "    local_dir=\"model\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "hKOPqdoj9tMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "from IPython.display import Audio, clear_output\n",
        "\n",
        "# Bật tắt lọc nhiễu (DeepFilterNet)\n",
        "denoise = False  # True = lọc nhiễu, False = giữ nguyên\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    if denoise:\n",
        "        !deepFilter --model DeepFilterNet3 \"{filename}\"\n",
        "        !ffmpeg -i \"{filename.replace('.wav', '_DeepFilterNet3.wav')}\" -ac 1 -ar 22050 -vn /content/model/user_sample.wav -y -hide_banner -loglevel error\n",
        "        os.remove(filename.replace('.wav', '_DeepFilterNet3.wav'))\n",
        "    else:\n",
        "        !ffmpeg -i \"{filename}\" -ac 1 -ar 22050 -vn /content/model/user_sample.wav -y -hide_banner -loglevel error\n",
        "    os.remove(filename)\n",
        "    break\n",
        "\n",
        "clear_output()\n",
        "print(\"✅ Đã tải file âm thanh thành công\")\n",
        "Audio(\"/content/model/user_sample.wav\")\n"
      ],
      "metadata": {
        "id": "6ZB9gsoY9tym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "oGSVcv3xuWWi",
        "outputId": "e2180384-113a-4374-cba8-0c72d8e1a9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'underthesea'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2477665155.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0munderthesea\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munidecode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munidecode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'underthesea'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# The inference code is adopted from https://github.com/coqui-ai/TTS/blob/dev/TTS/demos/xtts_ft_demo/xtts_demo.py\n",
        "# @title 2. 🤗 **Sử dụng**\n",
        "# @markdown 👈 Nhấn để chạy.\n",
        "# @markdown Nếu gặp lỗi thì cũng nhấn nút này nhé!\n",
        "\n",
        "# @markdown Lần đầu chạy sẽ hơi lâu, bạn chờ tí nhé!\n",
        "\n",
        "# @markdown Kết quả sẽ được lưu vào `/content/output`\n",
        "\n",
        "# @markdown Chọn ngôn ngữ:\n",
        "language = \"Tiếng Việt\" # @param [\"Tiếng Việt\", \"Tiếng Anh\",\"Tiếng Tây Ban Nha\", \"Tiếng Pháp\",\"Tiếng Đức\",\"Tiếng Ý\", \"Tiếng Bồ Đào Nha\", \"Tiếng Ba Lan\", \"Tiếng Thổ Nhĩ Kỳ\", \"Tiếng Nga\", \"Tiếng Hà Lan\", \"Tiếng Séc\", \"Tiếng Ả Rập\", \"Tiếng Trung (giản thể)\", \"Tiếng Nhật\", \"Tiếng Hungary\", \"Tiếng Hàn\", \"Tiếng Hindi\"]\n",
        "# @markdown Văn bản để đọc. Độ dài tối thiểu mỗi câu nên từ 10 từ để đặt kết quả tốt nhất.\n",
        "input_text =\"Xin chào, tôi là một công cụ có khả năng chuyển đổi văn bản thành giọng nói tự nhiên, được phát triển bởi nhóm Nón lá. Tôi có thể hổ trợ người khiếm thị,  đọc sách nói, làm trợ lý ảo, review phim, làm waifu để an ủi bạn, và phục vụ nhiều mục đích khác.\" # @param {type:\"string\"}\n",
        "# @markdown Chọn giọng mẫu:\n",
        "reference_audio = \"model/vi_sample.wav\" # @param [ \"model/user_sample.wav\",  \"model/vi_sample.wav\",  \"model/samples/nam-calm.wav\",  \"model/samples/nam-cham.wav\",  \"model/samples/nam-nhanh.wav\",  \"model/samples/nam-truyen-cam.wav\",  \"model/samples/nu-calm.wav\",  \"model/samples/nu-cham.wav\",  \"model/samples/nu-luu-loat.wav\",  \"model/samples/nu-nhan-nha.wav\",  \"model/samples/nu-nhe-nhang.wav\"]\n",
        "# @markdown Tự động chuẩn hóa chữ (VD: 20/11 -> hai mươi tháng mười một)\n",
        "normalize_text = True # @param {type:\"boolean\"}\n",
        "# @markdown In chi tiết xử lý\n",
        "verbose = True # @param {type:\"boolean\"}\n",
        "# @markdown Lưu từng câu thành file riêng lẻ.\n",
        "output_chunks = True # @param {type:\"boolean\"}\n",
        "\n",
        "from IPython.display import clear_output\n",
        "def cry_and_quit():\n",
        "    clear_output()\n",
        "    print(\"> Lỗi rồi huhu 😭😭, bạn hãy nhấn chạy lại phần này nhé!\")\n",
        "    quit()\n",
        "\n",
        "import os\n",
        "import string\n",
        "import unicodedata\n",
        "from datetime import datetime\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "from underthesea import sent_tokenize\n",
        "from unidecode import unidecode\n",
        "\n",
        "try:\n",
        "    from vinorm import TTSnorm\n",
        "    from TTS.tts.configs.xtts_config import XttsConfig\n",
        "    from TTS.tts.models.xtts import Xtts\n",
        "except:\n",
        "    cry_and_quit()\n",
        "\n",
        "# Load model\n",
        "def clear_gpu_cache():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "def load_model(xtts_checkpoint, xtts_config, xtts_vocab):\n",
        "    clear_gpu_cache()\n",
        "    if not xtts_checkpoint or not xtts_config or not xtts_vocab:\n",
        "        return \"You need to run the previous steps or manually set the `XTTS checkpoint path`, `XTTS config path`, and `XTTS vocab path` fields !!\"\n",
        "    config = XttsConfig()\n",
        "    config.load_json(xtts_config)\n",
        "    XTTS_MODEL = Xtts.init_from_config(config)\n",
        "    print(\"Loading XTTS model! \")\n",
        "    XTTS_MODEL.load_checkpoint(config,\n",
        "                               checkpoint_path=xtts_checkpoint,\n",
        "                               vocab_path=xtts_vocab,\n",
        "                               use_deepspeed=True)\n",
        "    if torch.cuda.is_available():\n",
        "        XTTS_MODEL.cuda()\n",
        "\n",
        "    print(\"Model Loaded!\")\n",
        "    return XTTS_MODEL\n",
        "\n",
        "\n",
        "def get_file_name(text, max_char=50):\n",
        "    filename = text[:max_char]\n",
        "    filename = filename.lower()\n",
        "    filename = filename.replace(\" \", \"_\")\n",
        "    filename = filename.translate(str.maketrans(\"\", \"\", string.punctuation.replace(\"_\", \"\")))\n",
        "    filename = unidecode(filename)\n",
        "    current_datetime = datetime.now().strftime(\"%m%d%H%M%S\")\n",
        "    filename = f\"{current_datetime}_{filename}\"\n",
        "    return filename\n",
        "\n",
        "\n",
        "def calculate_keep_len(text, lang):\n",
        "    if lang in [\"ja\", \"zh-cn\"]:\n",
        "        return -1\n",
        "\n",
        "    word_count = len(text.split())\n",
        "    num_punct = (\n",
        "        text.count(\".\")\n",
        "        + text.count(\"!\")\n",
        "        + text.count(\"?\")\n",
        "        + text.count(\",\")\n",
        "    )\n",
        "\n",
        "    if word_count < 5:\n",
        "        return 15000 * word_count + 2000 * num_punct\n",
        "    elif word_count < 10:\n",
        "        return 13000 * word_count + 2000 * num_punct\n",
        "    return -1\n",
        "\n",
        "\n",
        "def normalize_vietnamese_text(text):\n",
        "    text = (\n",
        "        TTSnorm(text, unknown=False, lower=False, rule=True)\n",
        "        .replace(\"..\", \".\")\n",
        "        .replace(\"!.\", \"!\")\n",
        "        .replace(\"?.\", \"?\")\n",
        "        .replace(\" .\", \".\")\n",
        "        .replace(\" ,\", \",\")\n",
        "        .replace('\"', \"\")\n",
        "        .replace(\"'\", \"\")\n",
        "        .replace(\"AI\", \"Ây Ai\")\n",
        "        .replace(\"A.I\", \"Ây Ai\")\n",
        "    )\n",
        "    return text\n",
        "\n",
        "\n",
        "def run_tts(XTTS_MODEL, lang, tts_text, speaker_audio_file,\n",
        "            normalize_text= True,\n",
        "            verbose=False,\n",
        "            output_chunks=False):\n",
        "    \"\"\"\n",
        "    Run text-to-speech (TTS) synthesis using the provided XTTS_MODEL.\n",
        "\n",
        "    Args:\n",
        "        XTTS_MODEL: A pre-trained TTS model.\n",
        "        lang (str): The language of the input text.\n",
        "        tts_text (str): The text to be synthesized into speech.\n",
        "        speaker_audio_file (str): Path to the audio file of the speaker to condition the synthesis on.\n",
        "        normalize_text (bool, optional): Whether to normalize the input text. Defaults to True.\n",
        "        verbose (bool, optional): Whether to print verbose information. Defaults to False.\n",
        "        output_chunks (bool, optional): Whether to save synthesized speech chunks separately. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the synthesized audio file.\n",
        "    \"\"\"\n",
        "\n",
        "    if XTTS_MODEL is None or not speaker_audio_file:\n",
        "        return \"You need to run the previous step to load the model !!\", None, None\n",
        "\n",
        "    output_dir = \"./output\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    gpt_cond_latent, speaker_embedding = XTTS_MODEL.get_conditioning_latents(\n",
        "        audio_path=speaker_audio_file,\n",
        "        gpt_cond_len=XTTS_MODEL.config.gpt_cond_len,\n",
        "        max_ref_length=XTTS_MODEL.config.max_ref_len,\n",
        "        sound_norm_refs=XTTS_MODEL.config.sound_norm_refs,\n",
        "    )\n",
        "\n",
        "    if normalize_text and lang == \"vi\":\n",
        "        # Bug on google colab\n",
        "        try:\n",
        "            tts_text = normalize_vietnamese_text(tts_text)\n",
        "        except:\n",
        "            cry_and_quit()\n",
        "\n",
        "    if lang in [\"ja\", \"zh-cn\"]:\n",
        "        tts_texts = tts_text.split(\"。\")\n",
        "    else:\n",
        "        tts_texts = sent_tokenize(tts_text)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Text for TTS:\")\n",
        "        pprint(tts_texts)\n",
        "\n",
        "    wav_chunks = []\n",
        "    for text in tqdm(tts_texts):\n",
        "        if text.strip() == \"\":\n",
        "            continue\n",
        "\n",
        "        wav_chunk = XTTS_MODEL.inference(\n",
        "            text=text,\n",
        "            language=lang,\n",
        "            gpt_cond_latent=gpt_cond_latent,\n",
        "            speaker_embedding=speaker_embedding,\n",
        "            temperature=0.3,\n",
        "            length_penalty=1.0,\n",
        "            repetition_penalty=10.0,\n",
        "            top_k=30,\n",
        "            top_p=0.85,\n",
        "        )\n",
        "\n",
        "        # Quick hack for short sentences\n",
        "        keep_len = calculate_keep_len(text, lang)\n",
        "        wav_chunk[\"wav\"] = torch.tensor(wav_chunk[\"wav\"][:keep_len])\n",
        "\n",
        "        if output_chunks:\n",
        "            out_path = os.path.join(output_dir, f\"{get_file_name(text)}.wav\")\n",
        "            torchaudio.save(out_path, wav_chunk[\"wav\"].unsqueeze(0), 24000)\n",
        "            if verbose:\n",
        "                print(f\"Saved chunk to {out_path}\")\n",
        "\n",
        "        wav_chunks.append(wav_chunk[\"wav\"])\n",
        "\n",
        "    out_wav = torch.cat(wav_chunks, dim=0).unsqueeze(0)\n",
        "    out_path = os.path.join(output_dir, f\"{get_file_name(tts_text)}.wav\")\n",
        "    torchaudio.save(out_path, out_wav, 24000)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Saved final file to {out_path}\")\n",
        "\n",
        "    return out_path\n",
        "\n",
        "\n",
        "language_code_map = {\n",
        "    \"Tiếng Việt\": \"vi\",\n",
        "    \"Tiếng Anh\": \"en\",\n",
        "    \"Tiếng Tây Ban Nha\": \"es\",\n",
        "    \"Tiếng Pháp\": \"fr\",\n",
        "    \"Tiếng Đức\": \"de\",\n",
        "    \"Tiếng Ý\": \"it\",\n",
        "    \"Tiếng Bồ Đào Nha\": \"pt\",\n",
        "    \"Tiếng Ba Lan\": \"pl\",\n",
        "    \"Tiếng Thổ Nhĩ Kỳ\": \"tr\",\n",
        "    \"Tiếng Nga\": \"ru\",\n",
        "    \"Tiếng Hà Lan\": \"nl\",\n",
        "    \"Tiếng Séc\": \"cs\",\n",
        "    \"Tiếng Ả Rập\": \"ar\",\n",
        "    \"Tiếng Trung (giản thể)\": \"zh-cn\",\n",
        "    \"Tiếng Nhật\": \"ja\",\n",
        "    \"Tiếng Hungary\": \"hu\",\n",
        "    \"Tiếng Hàn\": \"ko\",\n",
        "    \"Tiếng Hindi\": \"hi\"\n",
        "}\n",
        "\n",
        "print(\"> Đang nạp mô hình...\")\n",
        "try:\n",
        "    if not vixtts_model:\n",
        "        vixtts_model = load_model(xtts_checkpoint=\"model/model.pth\",\n",
        "                                xtts_config=\"model/config.json\",\n",
        "                                xtts_vocab=\"model/vocab.json\")\n",
        "except:\n",
        "    vixtts_model = load_model(xtts_checkpoint=\"model/model.pth\",\n",
        "                                xtts_config=\"model/config.json\",\n",
        "                                xtts_vocab=\"model/vocab.json\")\n",
        "clear_output()\n",
        "print(\"> Đã nạp mô hình\")\n",
        "\n",
        "if not os.path.exists(reference_audio):\n",
        "    print(\"⚠️⚠️⚠️Bạn chưa tải file âm thanh lên. Hãy chọn giọng khác, hoặc tải file của bạn lên ở bên dưới.⚠️⚠️⚠️\")\n",
        "    audio_file=\"/content/model/vi_sample.wav\"\n",
        "else:\n",
        "    audio_file = run_tts(vixtts_model,\n",
        "            lang=language_code_map[language],\n",
        "            tts_text=input_text,\n",
        "            speaker_audio_file=reference_audio,\n",
        "            normalize_text=normalize_text,\n",
        "            verbose=verbose,\n",
        "            output_chunks=output_chunks,)\n",
        "\n",
        "from IPython.display import Audio\n",
        "Audio(audio_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C7Bm9c2iTmpQ",
        "outputId": "1f04e63a-6a86-4396-fbe2-ac6e37e781f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-60dc5e3f-20b1-4e09-84f2-7ab2af23e082\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-60dc5e3f-20b1-4e09-84f2-7ab2af23e082\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving segment_12.wav to segment_12.wav\n",
            "/bin/bash: line 1: deepFilter: command not found\n",
            "\u001b[1;31msegment_12_DeepFilterNet3.wav: No such file or directory\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'segment_12_DeepFilterNet3.wav'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-299309245.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'deepFilter \"{filename}\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ffmpeg -i \"{filename.replace(\\'.wav\\', \\'_DeepFilterNet3.wav\\')}\" -ac 1 -ar 22050 -vn /content/model/user_sample.wav -y -hide_banner -loglevel error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_DeepFilterNet3.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ffmpeg -i \"{filename}\" -ac 1 -ar 22050 -vn /content/model/user_sample.wav -y -hide_banner -loglevel error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'segment_12_DeepFilterNet3.wav'"
          ]
        }
      ],
      "source": [
        "# @title 🎤 **Tải file âm thanh của bạn lên**\n",
        "# @markdown Để đạt chất lượng tốt nhất, hãy tham khảo file '/content/model/vi_sample.wav'\n",
        "# @\n",
        "import os\n",
        "import locale\n",
        "from google.colab import files\n",
        "\n",
        "denoise = True # @param {type:\"boolean\"}\n",
        "\n",
        "# Upload the audio file\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    # Convert the audio file to WAV format using ffmpeg\n",
        "    uploaded_dir = os.path.dirname(filename)\n",
        "    if denoise:\n",
        "        !deepFilter \"{filename}\"\n",
        "        !ffmpeg -i \"{filename.replace('.wav', '_DeepFilterNet3.wav')}\" -ac 1 -ar 22050 -vn /content/model/user_sample.wav -y -hide_banner -loglevel error\n",
        "        os.remove(filename.replace('.wav', '_DeepFilterNet3.wav'))\n",
        "    else:\n",
        "        !ffmpeg -i \"{filename}\" -ac 1 -ar 22050 -vn /content/model/user_sample.wav -y -hide_banner -loglevel error\n",
        "        os.remove(filename)\n",
        "    break\n",
        "\n",
        "from IPython.display import Audio, clear_output\n",
        "clear_output()\n",
        "print(\"> Đã tải file âm thanh lên\")\n",
        "Audio(\"/content/model/user_sample.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6sC6v6pNQVt5"
      },
      "outputs": [],
      "source": [
        "# @title ⏬ **Lưu kết quả vào Drive**\n",
        "# @markdown Chạy phần này để lưu kết quả vào Google Drive của bạn\n",
        "# @markdown `/content/drive/MyDrive/vixtts-output`\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save the output folder in \"vixtts-output\" in Google Drive, without overwriting existing files\n",
        "!cp -n -r /content/output/* /content/drive/MyDrive/vixtts-output\n",
        "print(\"> Đã lưu kết quả vào Google Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7-X619YbX0n-"
      },
      "outputs": [],
      "source": [
        "# @title ⚠️ **Dọn kết quả**\n",
        "# @markdown Chạy phần này để xóa toàn bộ file trong `/content/output`\n",
        "import shutil\n",
        "shutil.rmtree('/content/output')\n",
        "print(\"Đã xóa toàn bộ file trong /content/output\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 📴 **Tắt Demo**\n",
        "# @markdown Khi chạy xong thì bạn hãy tắt demo để tiết kiệm GPU nhé!\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "cvzEJ8c_PkRb"
      },
      "execution_count": 1,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}